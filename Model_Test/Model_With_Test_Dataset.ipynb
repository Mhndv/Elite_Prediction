{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXhjjEOLPBmB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Dataset ---\n",
        "df = pd.read_csv(\"/content/train_cleaned (3).csv\")  # adjust if path is different"
      ],
      "metadata": {
        "id": "62HcN1irPJdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse program age ranges\n",
        "age_split = df['Age Range by Program'].astype(str).str.extract(r'(?P<min_age>\\d+)-(?P<max_age>\\d+)')\n",
        "df['Program Min Age'] = age_split['min_age'].astype(float)\n",
        "df['Program Max Age'] = age_split['max_age'].astype(float)"
      ],
      "metadata": {
        "id": "EraHAxVePdot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age-based features\n",
        "df['Age In Range'] = df.apply(lambda row: 1 if row['Program Min Age'] <= row['Age'] <= row['Program Max Age'] else 0, axis=1)\n",
        "df['Age Gap To Min'] = df['Age'] - df['Program Min Age']\n",
        "df['Age Gap To Max'] = df['Program Max Age'] - df['Age']\n",
        "df['Extreme Age'] = df.apply(lambda row: 1 if row['Age'] < row['Program Min Age'] - 5 or row['Age'] > row['Program Max Age'] + 5 else 0, axis=1)"
      ],
      "metadata": {
        "id": "ULcdl_n8Pd4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop text column\n",
        "df.drop(columns=['Age Range by Program'], inplace=True)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df.drop(columns=['Student ID', 'Home City', 'Program ID', 'Program Start Date', 'Program End Date'], inplace=True, errors='ignore')"
      ],
      "metadata": {
        "id": "bEhfMljLPeRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Y'])\n",
        "y = df['Y'].map({0: 1, 1: 0})  # 1 = completed, 0 = quit"
      ],
      "metadata": {
        "id": "D--Q71iX5KTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode binary columns\n",
        "df['Completed Degree'] = df['Completed Degree'].map({'Yes': 1, 'No': 0})\n",
        "df['Still Working'] = df['Still Working'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].fillna('Unknown'))\n",
        "    label_encoders[col] = le  # Store the fitted LabelEncoder\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)  # Fit the scaler on training data\n"
      ],
      "metadata": {
        "id": "vPUfGQ-UPe4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "test_df = pd.read_csv('/content/test_cleaned (3).csv')\n",
        "\n",
        "age_split = test_df['Age Range by Program'].astype(str).str.extract(r'(?P<min_age>\\d+)-(?P<max_age>\\d+)')\n",
        "test_df['Program Min Age'] = age_split['min_age'].astype(float)\n",
        "test_df['Program Max Age'] = age_split['max_age'].astype(float)\n",
        "\n",
        "# Age-based features\n",
        "test_df['Age In Range'] = test_df.apply(lambda row: 1 if row['Program Min Age'] <= row['Age'] <= row['Program Max Age'] else 0, axis=1)\n",
        "test_df['Age Gap To Min'] = test_df['Age'] - test_df['Program Min Age']\n",
        "test_df['Age Gap To Max'] = test_df['Program Max Age'] - test_df['Age']\n",
        "test_df['Extreme Age'] = test_df.apply(lambda row: 1 if row['Age'] < row['Program Min Age'] - 5 or row['Age'] > row['Program Max Age'] + 5 else 0, axis=1)\n",
        "test_df['Y'] = test_df['Completed Degree'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "\n",
        "# Drop text column\n",
        "test_df.drop(columns=['Age Range by Program'], inplace=True)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "test_df.drop(columns=['Student ID', 'Home City', 'Program ID', 'Program Start Date', 'Program End Date'], inplace=True, errors='ignore')\n",
        "\n",
        "\n",
        "test_df['Completed Degree'] = test_df['Completed Degree'].map({'Yes': 1, 'No': 0})\n",
        "test_df['Still Working'] = test_df['Still Working'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Encode categorical columns using the same label encoders\n",
        "categorical_cols = test_df.select_dtypes(include='object').columns.tolist()\n",
        "for col in categorical_cols:\n",
        "    if col in label_encoders:\n",
        "        test_df[col] = label_encoders[col].transform(test_df[col])\n",
        "\n",
        "X_test = test_df.drop(columns=['Y'])\n",
        "y_test = test_df['Y']\n",
        "\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "id": "lLiTmezqPe_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model grids\n",
        "model_grids = {\n",
        "    \"Logistic Regression\": (\n",
        "        LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "        {\"C\": [0.01, 0.1, 1, 10]}\n",
        "    ),\n",
        "    \"SVM\": (\n",
        "        SVC(class_weight='balanced', probability=True),\n",
        "        {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
        "    ),\n",
        "    \"Random Forest\": (\n",
        "        RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "        {\"n_estimators\": [100, 200], \"max_depth\": [None, 10, 20]}\n",
        "    ),\n",
        "    \"Decision Tree\": (\n",
        "        DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "        {\"max_depth\": [None, 10, 20], \"min_samples_split\": [2, 5]}\n",
        "    ),\n",
        "     \"KNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]}\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "9b1OMX69PfGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, (model, params) in model_grids.items():\n",
        "    grid = GridSearchCV(model, params, scoring='f1', cv=5, n_jobs=-1)\n",
        "    grid.fit(X_scaled, y)\n",
        "    y_pred = grid.predict(X_test)\n",
        "    results[name] = {\n",
        "        \"Model\": name,\n",
        "        \"Best Params\": grid.best_params_,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred),\n",
        "        \"Best Estimator\": grid.best_estimator_\n",
        "    }\n",
        "\n",
        "# Prepare to save the best model\n",
        "results_df = pd.DataFrame(results).T.sort_values(by=\"F1 Score\", ascending=False)\n",
        "best_model_name = results_df.iloc[0][\"Model\"]\n",
        "best_model = results[best_model_name][\"Best Estimator\"]\n",
        "\n",
        "# Save the best model, scaler, and label encoders\n",
        "joblib.dump(best_model, \"best_model_extreme_age.pkl\")\n",
        "joblib.dump(scaler, \"scaler_extreme_age.pkl\")\n",
        "joblib.dump(label_encoders, \"label_encoders_extreme_age.pkl\")"
      ],
      "metadata": {
        "id": "mBrHYJjhQYC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"\\nBest model saved: {best_model_name}\")\n",
        "print(\"Files saved: best_model.pkl, scaler.pkl, label_encoders.pkl\\n\")\n",
        "print(\"Model Performance Summary:\")\n",
        "print(results_df.drop(columns='Best Estimator'))"
      ],
      "metadata": {
        "id": "BWrdHwm1QxCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming results_df is already defined and contains model performance metrics\n",
        "\n",
        "# Prepare the data for bar plot\n",
        "df_long = results_df.reset_index().melt(id_vars='Model',\n",
        "                          value_vars=['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "                          var_name='Metric', value_name='Score')\n",
        "\n",
        "# Create bar plot for model performance comparison\n",
        "fig = px.bar(df_long,\n",
        "             x='Model',\n",
        "             y='Score',\n",
        "             color='Metric',\n",
        "             barmode='group',\n",
        "             title='Model Performance Comparison',\n",
        "             text='Score',\n",
        "             height=600,\n",
        "             color_discrete_sequence=px.colors.sequential.Blues[2:]\n",
        "             )\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Model',\n",
        "    yaxis_title='Score',\n",
        "    legend_title='Metric',\n",
        "    font=dict(size=14),\n",
        "    plot_bgcolor='white',\n",
        "    yaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
        "    bargap=0.4\n",
        ")\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "WzvI2T7_Sk8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf_model = results[\"Random Forest\"][\"Best Estimator\"]\n",
        "y_pred_rf = best_rf_model.predict(X_test)  # Make sure X_test is defined\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rf)  # Ensure y_test is defined\n",
        "cm_percent = cm / cm.sum() * 100\n",
        "\n",
        "labels = [[\"TN\", \"FP\"], [\"FN\", \"TP\"]]\n",
        "annotations = [[f\"{label}<br>{value}<br>({percent:.1f}%)\"\n",
        "                for label, value, percent in zip(row_l, row_v, row_p)]\n",
        "               for row_l, row_v, row_p in zip(labels, cm, cm_percent)]\n",
        "\n",
        "# Create heatmap for confusion matrix\n",
        "fig_cm = go.Figure(data=go.Heatmap(\n",
        "    z=cm,\n",
        "    x=[\"Predicted Negative\", \"Predicted Positive\"],\n",
        "    y=[\"Actual Negative\", \"Actual Positive\"],\n",
        "    text=annotations,\n",
        "    texttemplate=\"%{text}\",\n",
        "    colorscale=\"Blues\",\n",
        "    showscale=True,\n",
        "    hoverinfo=\"skip\"\n",
        "))\n",
        "\n",
        "fig_cm.update_layout(\n",
        "    title=\"Confusion Matrix for Random Forest\",\n",
        "    xaxis_title=\"Predicted Label\",\n",
        "    yaxis_title=\"Actual Label\",\n",
        "    font=dict(size=18),\n",
        "    width=800,\n",
        "    height=550,\n",
        "    margin=dict(t=80, l=100, r=20, b=80)\n",
        ")\n",
        "\n",
        "fig_cm.show()"
      ],
      "metadata": {
        "id": "RlGwsaY5VAax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuhRcLpYeokx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}